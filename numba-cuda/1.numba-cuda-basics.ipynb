{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Numba for GPUs\n",
    "\n",
    "*Vasileios Karakasis, CSCS*\n",
    "\n",
    "You may use Numba to generate GPU code from high-level Python functions. Both CUDA and ROC GPUs (NVIDIA and AMD, respectively) are supported, but we are going to focus only on the CUDA capabilities of Numba.\n",
    "\n",
    "There is an almost one-to-one mapping between the Numba high-level Python abstractions and the different CUDA constructs. This practically means that, as a programmer, you need to take care explicitly of the host/device memory management and you need to be aware of the CUDA programming model.\n",
    "\n",
    "This demo will teach you to write your first CUDA kernels using Numba. It will cover the basic CUDA programming principles, but it should be enough to kick start you in GPU programming. More specifically, we will cover the following topics:\n",
    "\n",
    "- Writing a GPU kernel\n",
    "- Moving data to/from the GPU.\n",
    "- Spawning a GPU kernel\n",
    "- Profiling a GPU kernel\n",
    "- Optimizing memory accesses\n",
    "- Making use of the shared memory\n",
    "\n",
    "We will not cover CUDA streams.\n",
    "\n",
    "## Verify that Numba sees the GPU and understands CUDA\n",
    "\n",
    "First thing is to check if Numba can detect the GPU. You can achieve this by running the `numba` executable that comes with Numba's installation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System info:\n",
      "--------------------------------------------------------------------------------\n",
      "__Time Stamp__\n",
      "2019-11-08 17:52:16.872499\n",
      "\n",
      "__Hardware Information__\n",
      "Machine                                       : x86_64\n",
      "CPU Name                                      : haswell\n",
      "Number of accessible CPU cores                : 24\n",
      "Listed accessible CPUs cores                  : 0-23\n",
      "CFS restrictions                              : Information not available\n",
      "CPU Features                                  : \n",
      "64bit aes avx avx2 bmi bmi2 cmov cx16 f16c fma fsgsbase invpcid lzcnt mmx movbe\n",
      "pclmul popcnt rdrnd sahf sse sse2 sse3 sse4.1 sse4.2 ssse3 xsave xsaveopt\n",
      "\n",
      "__OS Information__\n",
      "Platform                                      : Linux-4.12.14-150.17_5.0.85-cray_ari_c-x86_64-with-glibc2.9\n",
      "Release                                       : 4.12.14-150.17_5.0.85-cray_ari_c\n",
      "System Name                                   : Linux\n",
      "Version                                       : #1 SMP Thu Aug 22 18:29:02 UTC 2019 (24c42de)\n",
      "OS specific info                              : \n",
      "glibc info                                    : glibc 2.9\n",
      "\n",
      "__Python Information__\n",
      "Python Compiler                               : GCC 7.2.0\n",
      "Python Implementation                         : CPython\n",
      "Python Version                                : 3.6.2\n",
      "Python Locale                                 : en_US UTF-8\n",
      "\n",
      "__LLVM information__\n",
      "LLVM version                                  : 8.0.0\n",
      "\n",
      "__CUDA Information__\n",
      "Found 1 CUDA devices\n",
      "id 0    b'Tesla P100-PCIE-16GB'                              [SUPPORTED]\n",
      "                      compute capability: 6.0\n",
      "                           pci device id: 0\n",
      "                              pci bus id: 2\n",
      "Summary:\n",
      "\t1/1 devices are supported\n",
      "CUDA driver version                           : 10010\n",
      "CUDA libraries:\n",
      "Finding cublas from Conda environment\n",
      "\tnamed  libcublas.so.10.2.1.243\n",
      "\ttrying to open library...\tok\n",
      "Finding cusparse from Conda environment\n",
      "\tnamed  libcusparse.so.10.3.0.243\n",
      "\ttrying to open library...\tok\n",
      "Finding cufft from Conda environment\n",
      "\tnamed  libcufft.so.10.1.1.243\n",
      "\ttrying to open library...\tok\n",
      "Finding curand from Conda environment\n",
      "\tnamed  libcurand.so.10.1.1.243\n",
      "\ttrying to open library...\tok\n",
      "Finding nvvm from Conda environment\n",
      "\tnamed  libnvvm.so.3.3.0\n",
      "\ttrying to open library...\tok\n",
      "Finding libdevice from Conda environment\n",
      "\tsearching for compute_20...\tok\n",
      "\tsearching for compute_30...\tok\n",
      "\tsearching for compute_35...\tok\n",
      "\tsearching for compute_50...\tok\n",
      "\n",
      "__ROC Information__\n",
      "ROC available                                 : False\n",
      "Error initialising ROC due to                 : No ROC toolchains found.\n",
      "No HSA Agents found, encountered exception when searching:\n",
      "Error at driver init: \n",
      "NUMBA_HSA_DRIVER /opt/rocm/lib/libhsa-runtime64.so is not a valid file path.  Note it must be a filepath of the .so/.dll/.dylib or the driver:\n",
      "\n",
      "__SVML Information__\n",
      "SVML state, config.USING_SVML                 : False\n",
      "SVML library found and loaded                 : False\n",
      "llvmlite using SVML patched LLVM              : True\n",
      "SVML operational                              : False\n",
      "\n",
      "__Threading Layer Information__\n",
      "TBB Threading layer available                 : True\n",
      "OpenMP Threading layer available              : True\n",
      "Workqueue Threading layer available           : True\n",
      "\n",
      "__Numba Environment Variable Information__\n",
      "None set.\n",
      "\n",
      "__Conda Information__\n",
      "conda_build_version                           : not installed\n",
      "conda_env_version                             : 4.7.12\n",
      "platform                                      : linux-64\n",
      "python_version                                : 3.6.2.final.0\n",
      "root_writable                                 : False\n",
      "\n",
      "__Current Conda Env__\n",
      "_libgcc_mutex             0.1                        main  \n",
      "asn1crypto                1.2.0                    py36_0  \n",
      "backcall                  0.1.0                    py36_0    anaconda\n",
      "blas                      1.0                         mkl  \n",
      "bokeh                     1.4.0                    py36_0  \n",
      "ca-certificates           2019.10.16                    0    anaconda\n",
      "cairo                     1.14.12              h8948797_3  \n",
      "certifi                   2019.9.11                py36_0    anaconda\n",
      "cffi                      1.13.1           py36h2e261b9_0    anaconda\n",
      "chardet                   3.0.4                 py36_1003  \n",
      "click                     7.0                      py36_0  \n",
      "cloudpickle               1.2.2                      py_0  \n",
      "conda                     4.7.12                   py36_0    anaconda\n",
      "conda-package-handling    1.6.0            py36h7b6447c_0  \n",
      "cryptography              2.3.1            py36hc365091_0  \n",
      "cudatoolkit               10.1.243             h6bb024c_0  \n",
      "cudnn                     7.6.4                cuda10.1_0    anaconda\n",
      "cupy                      6.0.0            py36hc0ce245_0    anaconda\n",
      "cupy-cuda101              6.5.0                    pypi_0    pypi\n",
      "cycler                    0.10.0                     py_2    conda-forge\n",
      "cython                    0.29.13          py36he6710b0_0    anaconda\n",
      "cytoolz                   0.10.0           py36h7b6447c_0  \n",
      "dask                      2.6.0                      py_0  \n",
      "dask-core                 2.6.0                      py_0  \n",
      "dbus                      1.13.2               h714fa37_1  \n",
      "decorator                 4.4.1                      py_0    anaconda\n",
      "distributed               2.6.0                      py_0  \n",
      "expat                     2.2.5             he1b5a44_1004    conda-forge\n",
      "fastrlock                 0.4              py36he6710b0_0    anaconda\n",
      "fontconfig                2.13.0               h9420a91_0  \n",
      "freetype                  2.9.1                h8a8886c_1  \n",
      "fribidi                   1.0.5             h516909a_1002    conda-forge\n",
      "fsspec                    0.5.2                      py_0  \n",
      "gettext                   0.19.8.1          hc5be6a0_1002    conda-forge\n",
      "glib                      2.56.2            had28632_1001    conda-forge\n",
      "graphite2                 1.3.13            hf484d3e_1000    conda-forge\n",
      "graphviz                  2.40.1               h21bd128_2  \n",
      "gst-plugins-base          1.14.0               hbbd80ab_1  \n",
      "gstreamer                 1.14.0               hb453b48_1  \n",
      "harfbuzz                  1.9.0             he243708_1001    conda-forge\n",
      "heapdict                  1.0.1                      py_0  \n",
      "icu                       58.2              hf484d3e_1000    conda-forge\n",
      "idna                      2.8                      py36_0  \n",
      "intel-openmp              2019.4                      243  \n",
      "ipykernel                 5.1.3            py36h39e3cac_0    anaconda\n",
      "ipyparallel               6.2.4                    py36_0    anaconda\n",
      "ipython                   7.9.0            py36h39e3cac_0    anaconda\n",
      "ipython_genutils          0.2.0                    py36_0    anaconda\n",
      "jedi                      0.15.1                   py36_0    anaconda\n",
      "jinja2                    2.10.3                     py_0  \n",
      "jpeg                      9b                   h024ee3a_2  \n",
      "jupyter_client            5.3.4                    py36_0    anaconda\n",
      "jupyter_core              4.6.0                    py36_0    anaconda\n",
      "kiwisolver                1.1.0            py36hc9558a2_0    conda-forge\n",
      "libedit                   3.1                  heed3624_0  \n",
      "libffi                    3.2.1                hd88cf55_4  \n",
      "libgcc-ng                 8.2.0                hdf63c60_1  \n",
      "libgfortran-ng            7.3.0                hdf63c60_0  \n",
      "libiconv                  1.15              h516909a_1005    conda-forge\n",
      "libpng                    1.6.37               hbc83047_0  \n",
      "libsodium                 1.0.16               h1bed415_0    anaconda\n",
      "libstdcxx-ng              8.2.0                hdf63c60_1  \n",
      "libtiff                   4.0.10               h2733197_2  \n",
      "libuuid                   1.0.3                h1bed415_2  \n",
      "libxcb                    1.13              h14c3975_1002    conda-forge\n",
      "libxml2                   2.9.9                hea5a465_1  \n",
      "llvmlite                  0.30.0           py36hd408876_0  \n",
      "locket                    0.2.0                    py36_1  \n",
      "markupsafe                1.1.1            py36h7b6447c_0  \n",
      "matplotlib                3.1.1            py36h5429711_0  \n",
      "mkl                       2019.4                      243  \n",
      "mkl-service               2.3.0            py36he904b0f_0  \n",
      "mkl_fft                   1.0.15           py36ha843d7b_0  \n",
      "mkl_random                1.1.0            py36hd6b4f25_0  \n",
      "mpi4py                    3.0.3                    pypi_0    pypi\n",
      "msgpack-python            0.6.1            py36hfd86e86_1  \n",
      "nccl                      1.3.5                cuda10.0_0    anaconda\n",
      "ncurses                   6.0                  h9df7e31_2  \n",
      "numba                     0.46.0           py36h962f231_0  \n",
      "numexpr                   2.7.0            py36h9e4a6bb_0    anaconda\n",
      "numpy                     1.17.3           py36hd14ec0e_0  \n",
      "numpy-base                1.17.3           py36hde5b4d6_0  \n",
      "olefile                   0.46                     py36_0  \n",
      "openssl                   1.0.2t               h7b6447c_1    anaconda\n",
      "packaging                 19.2                       py_0  \n",
      "pandas                    0.25.2           py36he6710b0_0  \n",
      "pango                     1.42.4               h049681c_0  \n",
      "parso                     0.5.1                      py_0    anaconda\n",
      "partd                     1.0.0                      py_0  \n",
      "pcre                      8.43                 he1b5a44_0    conda-forge\n",
      "pexpect                   4.7.0                    py36_0    anaconda\n",
      "pickleshare               0.7.5                    py36_0    anaconda\n",
      "pillow                    6.2.1            py36h34e0f95_0  \n",
      "pip                       19.3.1                   py36_0  \n",
      "pixman                    0.38.0            h516909a_1003    conda-forge\n",
      "prompt_toolkit            2.0.10                     py_0    anaconda\n",
      "psutil                    5.6.3            py36h7b6447c_0  \n",
      "pthread-stubs             0.4               h14c3975_1001    conda-forge\n",
      "ptyprocess                0.6.0                    py36_0    anaconda\n",
      "pycosat                   0.6.3            py36h14c3975_0  \n",
      "pycparser                 2.19                     py36_0  \n",
      "pygments                  2.4.2                      py_0    anaconda\n",
      "pyopenssl                 19.0.0                   py36_0  \n",
      "pyparsing                 2.4.2                      py_0  \n",
      "pyqt                      5.9.2            py36h05f1152_2  \n",
      "pysocks                   1.7.1                    py36_0  \n",
      "python                    3.6.2               hca45abc_19  \n",
      "python-dateutil           2.8.0                    py36_0  \n",
      "python-graphviz           0.13                       py_0    conda-forge\n",
      "pytz                      2019.3                     py_0  \n",
      "pyyaml                    5.1.2            py36h7b6447c_0  \n",
      "pyzmq                     18.1.0           py36he6710b0_0    anaconda\n",
      "qt                        5.9.6                h52aff34_0  \n",
      "readline                  7.0                  ha6073c6_4  \n",
      "requests                  2.22.0                   py36_0  \n",
      "ruamel_yaml               0.15.46          py36h14c3975_0  \n",
      "scipy                     1.3.1            py36h7c811a0_0    anaconda\n",
      "setuptools                41.6.0                   py36_0  \n",
      "sip                       4.19.8          py36hf484d3e_1000    conda-forge\n",
      "six                       1.12.0                   py36_0  \n",
      "sortedcontainers          2.1.0                    py36_0  \n",
      "sqlite                    3.23.1               he433501_0  \n",
      "tbb                       2019.8               hfd86e86_0  \n",
      "tblib                     1.4.0                      py_0  \n",
      "tk                        8.6.8                hbc83047_0  \n",
      "toolz                     0.10.0                     py_0  \n",
      "tornado                   6.0.3            py36h7b6447c_0  \n",
      "tqdm                      4.36.1                     py_0  \n",
      "traitlets                 4.3.3                    py36_0    anaconda\n",
      "urllib3                   1.24.2                   py36_0  \n",
      "wcwidth                   0.1.7                    py36_0    anaconda\n",
      "wheel                     0.33.6                   py36_0  \n",
      "xorg-libxau               1.0.9                h14c3975_0    conda-forge\n",
      "xorg-libxdmcp             1.1.3                h516909a_0    conda-forge\n",
      "xz                        5.2.4                h14c3975_4  \n",
      "yaml                      0.1.7                had09818_2  \n",
      "zeromq                    4.3.1                he6710b0_3    anaconda\n",
      "zict                      1.0.0                      py_0  \n",
      "zlib                      1.2.11               h7b6447c_3  \n",
      "zstd                      1.3.7                h0b5b093_0  \n",
      "--------------------------------------------------------------------------------\n",
      "If requested, please copy and paste the information between\n",
      "the dashed (----) lines, or from a given specific section as\n",
      "appropriate.\n",
      "\n",
      "=============================================================\n",
      "IMPORTANT: Please ensure that you are happy with sharing the\n",
      "contents of the information present, any information that you\n",
      "wish to keep private you should remove before sharing.\n",
      "=============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!numba -s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this command does not work out of the box for your Numba installation, you may have to set the `CUDA_HOME` environment variable to point to your CUDA installation.\n",
    "\n",
    "## Writing the first kernel\n",
    "\n",
    "Here is a vector addition kernel that takes two vectors as input and writes the sum in a third vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba.cuda as cuda\n",
    "\n",
    "\n",
    "@cuda.jit\n",
    "def _vecadd_cuda(z, x, y):\n",
    "    i = cuda.grid(1)\n",
    "    N = x.shape[0]\n",
    "    if i >= N:\n",
    "        return\n",
    "\n",
    "    z[i] = x[i] + y[i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty simple, right? Let's explain each line of this code.\n",
    "\n",
    "The `@cuda.jit` decorator will compile the following function into a CUDA kernel at runtime. We will see the cost of it later on.\n",
    "\n",
    "A CUDA kernel in Numba is a Python function that does *not* return a value. This is in accordance with CUDA, where kernel functions are declared `void`. The arguments of the function can be either Numpy arrays or scalars of a Numba recognized type.\n",
    "\n",
    "CUDA kernels specify the work to be done by a single GPU thread. Due to the massive hardware parallelism available on the GPU, a single GPU thread gets only a tiny portion of work, in this case, the sumation of a single element in the vectors. Since each element is independent from each other, we can safely create as many threads as the elements of the target vectors and spawn them (we will see how later).\n",
    "\n",
    "Threads on the GPU as organized in groups, called CUDA blocks. There are constraints on the maximum number of threads a block can contain. For the P100 GPUs on Daint, this is 1024. This means that you will need multiple blocks to calculate the sum of large vectors. The blocks that comprise a kernel form the *grid*. Threads inside a block are numbered sequentially and the blocks inside the grid are numbered, too. The figure below shows the arrangement of threads for the vector addition example.\n",
    "\n",
    "![Arrangement of threads in CUDA blocks](figs/cuda-blocks.png)\n",
    "\n",
    "In order to obtain the i-th element of the vector given a block size $B$, you would have to calculate the following:\n",
    "\n",
    "\\begin{equation}\n",
    "i = i_{b}B + i_{t}\n",
    "\\end{equation}\n",
    "\n",
    "where $i_{b}$ is the block index and $i_{t}$ is the thread index. CUDA provides this information and Numba makes it available, so that the above statement would be written as follows:\n",
    "\n",
    "```python\n",
    "i = cuda.blockIdx.x*cuda.blockDim.x + threadIdx.x\n",
    "```\n",
    "\n",
    "Blocks and grids can be three dimensional, thus the `.x` attribute in all of these variables (the other dimensions are accessed through the `.y` and `.z` attributes).\n",
    "\n",
    "Since obtaining the absolute position of a thread in a CUDA is quite common operation, Numba offers the convenience function `grid()`, which essentially does automatically the above calculation:\n",
    "\n",
    "```python\n",
    "i = cuda.grid(1)\n",
    "```\n",
    "\n",
    "The argument passed to the `grid()` function is the number of dimensions of the grid.\n",
    "\n",
    "The next three statements in the code simply check that we don't overrun the arrays in case that their dimension is not a multiple of the block size. In this case, some threads of the last block will remain idle:\n",
    "\n",
    "```python\n",
    "    N = x.shape[0]\n",
    "    if i >= N:\n",
    "        return\n",
    "```\n",
    "\n",
    "> The threads inside a block are run in batches of 32 at once, called *warps*. All the threads of the warp execute the same instruction. If the program control flow diverges for some of the threads of the warp, e.g., due to an `if` condition, the branches will be executed sequentially by disabling the non participating threads. This condition is called *warp divergence* and may incur a performance penalty.\n",
    "\n",
    "Finally, the `z[i] = x[i] + y[i]` computes the actual sum.\n",
    "\n",
    "\n",
    "## Preparing the data for the GPU\n",
    "\n",
    "All Numba CUDA kernels operate on data residing on the GPU. That means that the `x`, `y` and `z` arrays must be  transferred from the host (CPU) to the device (accelerator) before calling the CUDA kernel.\n",
    "\n",
    "Let's create first two vectors on the host:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "N = 1024\n",
    "x = np.random.rand(N)\n",
    "y = np.random.rand(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also compute our reference result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_ref = x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to transfer the vectors to the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_x = cuda.to_device(x)\n",
    "d_y = cuda.to_device(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `d_x` and `d_y` are Numpy *array-like* objects that have their data mapped in the GPU memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<numba.cuda.cudadrv.devicearray.DeviceNDArray at 0x2aaab3fa7ef0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the `z` array, we don't need to create it on the host and copy it, since it is essentially an output only array. We can simply allocate it directly on the GPU and copy it out when the kernel finishes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_z = cuda.device_array_like(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will simply allocate an array like `x`, i.e., with the same element type, shape and order, on the GPU.\n",
    "\n",
    "Data is ready, now it's time to call the kernel!\n",
    "\n",
    "## Invoking a CUDA kernel\n",
    "\n",
    "When invoking a CUDA kernel you have to specify the block size to use and the corresponding grid size. Picking the right size of block is not always straightforward, but usually values between 64 and 256 are good enough. \n",
    "\n",
    "> The block size has a direct effect on the *occupancy* of each GPU SM, i.e., how much the actual hardware threads of the SM are utilized, and as a result to the occupancy of the whole GPU. Performance-wise, though, it does not have such a big impact. Nvidia provides a nice tool for calculating the occupancy of the GPU, that you can find [here](https://docs.nvidia.com/cuda/cuda-occupancy-calculator/CUDA_Occupancy_Calculator.xls).\n",
    "\n",
    "For our kernel, we will select a block size of 128 threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having decided the block size we need to set up the grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_blocks = N // block_size\n",
    "if N % block_size:\n",
    "    num_blocks += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to call the kernel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_vecadd_cuda[num_blocks, block_size](d_z, d_x, d_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the block and the grid could have been two-dimensional (not in this example), in which case you would just define them as tuples.\n",
    "\n",
    "## Copying back the results\n",
    "\n",
    "As mentioned before, kernels operate on GPU data only. We need a way to transfer back to the host the result, which is the `d_z` array. Here's how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = d_z.copy_to_host()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's validate the result though to make sure that everything has worked fine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(z_ref, res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "\n",
    "For completeness and easy reference, here is the whole vector addition example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba.cuda as cuda\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "@cuda.jit\n",
    "def _vecadd_cuda(z, x, y):\n",
    "    '''The CUDA kernel'''\n",
    "    i = cuda.grid(1)\n",
    "    N = x.shape[0]\n",
    "    if i >= N:\n",
    "        return\n",
    "\n",
    "    z[i] = x[i] + y[i]\n",
    "\n",
    "\n",
    "# Set up the host vectors\n",
    "N = 1000\n",
    "x = np.random.rand(N)\n",
    "y = np.random.rand(N)\n",
    "\n",
    "# Copy and allocate data on the device\n",
    "d_x = cuda.to_device(x)\n",
    "d_y = cuda.to_device(y)\n",
    "d_z = cuda.device_array_like(x)\n",
    "\n",
    "# Set up the kernel invocation\n",
    "block_size = 128\n",
    "num_blocks = N // block_size\n",
    "if N % block_size:\n",
    "    num_blocks += 1\n",
    "\n",
    "# Call the kernel\n",
    "_vecadd_cuda[num_blocks, block_size](d_z, d_x, d_y)\n",
    "\n",
    "# Copy back the result to the host\n",
    "res = d_z.copy_to_host()\n",
    "\n",
    "# Validate the result\n",
    "assert np.allclose(x + y, res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "> 1. Make the array sufficiently large and time the Numpy version of the sum `x + y`.\n",
    "> 2. Now time the call to the CUDA kernel with `%timeit -n1 -r1`. What do you see?\n",
    "> 3. Try timing the CUDA kernels with `%timeit -n1 -r2`. What is happening?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miniconda-pythonhpc",
   "language": "python",
   "name": "miniconda-pythonhpc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
